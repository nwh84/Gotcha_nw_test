---
title: "GoTChA_pipeline"
output: html_document
---

# Running Gotcha with parallel computing in slurm

This is a tutorial for processing [GoT-ChA](https://www.biorxiv.org/content/10.1101/2022.05.11.491515v1.full.pdf) genotyping libraries. The Gotcha R package required for this tutorial can be downloaded [here](https://github.com/landau-lab/Gotcha) 

## Use of BatchMutationCalling function

### First, we load the Gotcha R library and rslurm:

```{r}
library(Gotcha)
library(rslurm)
```

### Then, we can define the paths and inputs for the pipeline

```{r}
path_to_fastqs = "/sc/arion/projects/MDS/noelle/gotcha_pipeline_nwheeler/Gotcha_test_pipeline/GoTChA_test_data/gotcha_test_data_subset2"
path_out = "/sc/arion/projects/MDS/noelle/gotcha_pipeline_nwheeler/Gotcha_test_pipeline/out_data/"

barcodes.file.path = "/gpfs/commons/home/tbotella/GOTCHA/MPN15_16_CMP53/MPN15/MPN15_new_ATAC/outs/singlecell.csv"

```



### We are now ready to run the pipeline

```{r}
# Split the fastq files in chunks to allow for parallel processing and filter out reads that contain low quality scores,
# particularly at the mutation site of interest


FastqFiltering(path = path_to_fastqs, 
               out = path_out, 
               min.quality = 15, 
               min.bases =1, 
               which.read= "R1", 
               read.region = c(1:50), 
               ncores=20)

bsub_opt$temp_dir <- "/sc/arion/projects/MDS/gotcha_pipeline_nwheeler/Gotcha_test_pipeline/bsub_test_dir"

bsub_opt$bsub_template = function(name, hours, memory, cores, ...) {
    glue::glue("bsub -J '{name}' -W '{hours}:00' -n {cores} -R 'rusage[mem={memory}GB]' -P 'project_name'")
}

# Run Gotcha with parallel computing in slurm: submit one cluster job per fastq chunk
BatchMutationCalling(out  = "/sc/arion/projects/MDS/noelle/gotcha_pipeline_nwheeler/Gotcha_test_pipeline/GoTChA_test_data/gotcha_test_data_subset2/",
                     which.read = "R1",
                     mutation.start = 1, # take the whole read
                     mutation.end = 50, 
                     barcodes.file.path = "/sc/arion/projects/MDS/noelle/gotcha_pipeline_nwheeler/Gotcha_test_pipeline/GoTChA_test_data/gotcha_test_data_subset/CBNN_0_singlecell.csv",
                     primer.sequence = "A", # this checks the match for the intial nucleotides
                     primed.max.mismatch = 1, # putting 1 here allows one nucleotide mismatch a thus primer matching should not eliminate any reads as we only put 1 nucleotide anyway
                     wt.sequence = "GCATGTATGCAATGCCTTGGTAGGAATGGGACAGGTGTAGGATGGAAAAT", 
                     mut.sequence= "AAGGCGTTTCTTCTCTGACCGCACAACTGGGGCCTGGGGGGCTCCAAAGC",
                     wt.max.mismatch = 0, # set up on perfect matching for increased accuracy
                     mut.max.mismatch = 0,
                     ncores = 10
)

```

### Once the submitted jobs are completed, we can merge the outputs into one single data frame using the MergeMutationCalling function. 
```{r}
#Merge output from each BatchMutationCalling job. 
#Generate a new folder containing a .Rdata class object that can be directly loaded into R
MergeMutationCalling(out = path_out)
```

### We can then load the output from the MutationCalling function
```{r}
load(paste0(path_out,'Split/Filtered/MergedOuts/outs.collapsed.Rdata'))
outs.collapse$Sample = sample_id
write.csv(outs.collapse,paste0(path_out,'/metadata_',sample_id,'.csv'), row.names = T)
```

### And run the GotchaLabeling function for noise correction and genotype labeling

## Noise Correction and Genotype Labeling
```{r}
#Use wild type and mutant read counts to predict genotype
gotcha_labels <- GotchaLabeling(path=paste0(path_out,'/'), infile = paste0('metadata_',sample_id,'.csv'), gene_id = gene_id, sample_id = sample_id)

saveRDS(gotcha_labels, paste0(path_out,'/gotcha_labels_',sample_id,'.Rds'))
write.csv(as.data.frame(gotcha_labels), paste0(path_out,'/gotcha_labels_',sample_id,'.csv'))
```
```

